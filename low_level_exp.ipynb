{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import audb\n",
    "import audiofile\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "from matplotlib import pyplot as plt\n",
    "import opensmile\n",
    "\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split #train/test split \n",
    "from sklearn.svm import SVC #Model\n",
    "from sklearn.metrics import confusion_matrix #Metrics \n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.model_selection import cross_val_score #Cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import scipy\n",
    "import random #for shuffling values \n",
    "from scipy import stats\n",
    "\n",
    "#List of prosodic features we will observe\n",
    "\n",
    "features_prosody= ['Loudness_sma3', \n",
    "                   'hammarbergIndex_sma3',\n",
    "                   'F0semitoneFrom27.5Hz_sma3nz',\n",
    "                    'slope0-500_sma3',\n",
    "                  'slope500-1500_sma3',\n",
    "                   'jitterLocal_sma3nz',\n",
    " 'shimmerLocaldB_sma3nz',\n",
    " 'HNRdBACF_sma3nz',\n",
    " 'mfcc1_sma3',\n",
    " 'mfcc2_sma3',\n",
    " 'mfcc3_sma3',\n",
    " 'mfcc4_sma3']\n",
    "\n",
    "# Function to perform one-hot encoding\n",
    "def encode(label):\n",
    "    if 'non-hate' in label:\n",
    "        return 0\n",
    "    elif 'hate' in label:\n",
    "        return 1\n",
    "\n",
    "#Gets low-level features of all audios \n",
    "def lowlevel_features(list_with_files):\n",
    "    path= \"data/clean_audio1/\"\n",
    "    \n",
    "    #  Define feature extractor\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.LowLevelDescriptors,\n",
    "    )\n",
    "\n",
    "    df_data= []\n",
    "\n",
    "    for i in (list_with_files):\n",
    "        f= path + i\n",
    "        sampling_rate, data = read_wav(f) #gets sampling rate and dimensions of data\n",
    "        #print(f\"Sampling rate of {f}:{sampling_rate}\")\n",
    "        \n",
    "        db = audb.load('emodb',\n",
    "        version='1.1.1',\n",
    "        format='wav',\n",
    "        mixdown=True,\n",
    "        sampling_rate=sampling_rate,\n",
    "        media='wav/03a01.*',  # load subset\n",
    "        full_path=False,\n",
    "        verbose=False,)\n",
    "\n",
    "        #extract features\n",
    "        signal, sampling_rate = audiofile.read(f, duration=120, always_2d=True)\n",
    "        data= smile.process_signal(signal, sampling_rate)\n",
    "        df_data.append(data.loc[:,features_prosody].values)\n",
    "\n",
    "   # df= pd.concat(df_data, ignore_index=True)\n",
    "    return df_data\n",
    "        \n",
    "def t_test(dataframe):\n",
    "    for i in features_prosody:\n",
    "        class_0= dataframe[i][dataframe['label']==0].values\n",
    "        class_1= dataframe[i][dataframe['label']== 1].values \n",
    "        t_statistic, p_value = stats.ttest_ind(class_0, class_1)\n",
    "        print(f\"T-statistic {i}:\", t_statistic)\n",
    "        print(f\"P-value {i}:\", p_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
      " 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/datasets/data_spanish_dataset.csv\")\n",
    "\n",
    "# Encoding categorical variables. Not hate speech = 0. Hate speech = 1. \n",
    "df['label'] = df['label'].apply(lambda x: encode(x))\n",
    "\n",
    "#Storing labels in array \n",
    "labels= df['label'].values\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process wav files \n",
    "path=\"data/clean_audio1\"\n",
    "dir_list = os.listdir(path)\n",
    "feature_data= lowlevel_features(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the shape of the largest matrix\n",
    "max_shape = max(matrix.shape for matrix in feature_data)\n",
    "\n",
    "# Zero-pad the rows of matrices\n",
    "padded_matrices = []\n",
    "for matrix in feature_data:\n",
    "    pad_width = ((0, max_shape[0] - matrix.shape[0]), (0, 0))\n",
    "    padded_matrix = np.pad(matrix, pad_width, mode='constant', constant_values=0)\n",
    "    padded_matrices.append(padded_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n",
      "(11996, 12)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of padded matrices\n",
    "for matrix in padded_matrices:\n",
    "    print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test split \n",
    "y= labels\n",
    "#y= y_axis.to_numpy().flatten() #Labels (class 0 and 1)\n",
    "X = np.asarray(padded_matrices)\n",
    "X= X.reshape(-1, X.shape[1]*X.shape[2])\n",
    "#X= X_axis.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 143952)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Max. recall:0.5\n",
      "Optimal C: 1e-05\n",
      "Optimal gamma:1e-05\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation recall\n",
    "\n",
    "C_list= np.logspace(-5, 5, 20)\n",
    "gamma_list= np.logspace(-5, 5, 20)\n",
    "recall = np.zeros((len(C_list), len(gamma_list)))\n",
    "\n",
    "\n",
    "for i in range(len(C_list)):\n",
    "     print(f'Iteration {i}')\n",
    "     for j in range(len(gamma_list)):\n",
    "        svc= SVC(C=C_list[i], gamma=gamma_list[j], kernel='rbf')\n",
    "        svc.fit(X_train, y_train)\n",
    "        y_pred= svc.predict(X_val)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "        recall[i, j] = float(tp+tn) / (tp + fn + fp + tn)\n",
    "               \n",
    "\n",
    "index_max = np.unravel_index(np.argmax(recall), recall.shape)\n",
    "\n",
    "print('Max. recall:{}'.format(recall[index_max]))\n",
    "C_opt = C_list[index_max[0]]\n",
    "gamma_opt = gamma_list[index_max[1]]\n",
    "print('Optimal C: {}'.format(C_opt))\n",
    "print('Optimal gamma:{}'.format(gamma_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 4],\n",
       "       [5, 5]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc= SVC(kernel='rbf', class_weight='balanced', C=C_opt, gamma=gamma_opt)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall mean: 0.63\n",
      "Recall standard deviation: 0.1004987562112089\n"
     ]
    }
   ],
   "source": [
    "#Validation of model (recall)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "scores = [] \n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train_k, y_train_k = X[train_idx], y[train_idx]\n",
    "    X_val_k, y_val_k = X[val_idx], y[val_idx]\n",
    "    svc= SVC(C=C_opt, gamma=gamma_opt, kernel='rbf', class_weight='balanced')\n",
    "    svc.fit(X_train_k, y_train_k)\n",
    "    y_pred_k= svc.predict(X_val_k)\n",
    "    cm= confusion_matrix(y_val_k, y_pred_k)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_k, y_pred_k).ravel()\n",
    "    recall_v = float(tp+tn) / (tp + fn + fp + tn)\n",
    "    scores.append(recall_v)\n",
    "\n",
    "print('Recall mean: {}'.format(np.mean(scores))) \n",
    "print('Recall standard deviation: {}'.format(np.std(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
